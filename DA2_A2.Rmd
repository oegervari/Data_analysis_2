---
title: "DA2 - Assignment 2"
output:
  html_document:
    df_print: paged
  pdf_document:
    extra_dependencies: ["float"]
---

```{r setup, include=FALSE, warning=F}
knitr::opts_chunk$set(fig.pos = "!H", out.extra = "")
# Set graph size
knitr::opts_chunk$set(echo = FALSE, out.width = "50%", fig.asp = 0.5, fig.width = 7, out.width = "90%" )

rm(list=ls())

# Libraries
library(tidyverse)
library(modelsummary)
library(fixest)
library(ggpubr)
library(lspline)
library(mfx)

# Get the data
hotels_europe_price <- read_csv("https://osf.io/p6tyr/download")
hotels_europe_features <- read_csv("https://osf.io/utwjs/download")

data <- left_join(hotels_europe_price, hotels_europe_features, by = "hotel_id")
rm(hotels_europe_price,hotels_europe_features)

```

## Introduction

In this analysis I investigate whether there is a relationship between hotels' (high) rating and their stars and distances to the city center. I used the [hotel-europe dataset](https://osf.io/p6tyr/) with the location set to Berlin. 


```{r, echo=FALSE}
# Sample selection
data <- data %>% filter(city_actual == 'Berlin')
data$highly_rated <- ifelse(data$rating >= 4, 1, 0)

asd <- summary(data$highly_rated)  #  mean is 0.6, means that 60% of hotels are highly rated
```

I created a binary variable based on the hotel ratings, if a hotel is rated 4 or above, the highly_rated column takes a value of 1, in other cases 0. Based on this, the mean value of this variable for the dataset is `r asd[4]`. That is also the probability of a hotel being highly rated in Berlin.

As the next step, I calculated the predictions of high rating (of hotels) using the linear probability, logit and probit models and plotted the results in the following graph.

```{r, echo=FALSE, warning=FALSE, fig.width=8, fig.height = 3, fig.align="center", message=F }
model_formula <- formula( highly_rated ~ distance + stars )

lpm <- feols(model_formula, data = data, vcov = 'hetero')

pred_lpm <- predict(lpm)

#logit coefficients
logit <- feglm(model_formula, data = data, family = binomial( link = "logit" ))

# predicted logit probabilities
pred_logit <- predict(logit)

#Logit marginal differences
logit_marg <- logitmfx( model_formula, data=data, atmean=FALSE, robust = T )


#probit coefficients
probit <- feglm(model_formula, data = data, family = binomial( link = "probit" ))

# predicted probit probabilities
pred_probit <- predict(probit)

#Probit marginal differences
probit_marg <- probitmfx( model_formula, data=data, atmean=FALSE, robust = T )

# Comparing predicted probabilities of logit and probit to LPM
ggplot(data = data[1:4200,]) +
  geom_point(aes(x=pred_lpm, y=pred_probit, color="Probit"), size=0.7,  shape=16) +
  geom_point(aes(x=pred_lpm, y=pred_logit,  color="Logit"), size=0.7,  shape=16) +
  geom_line(aes(x=pred_lpm, y=pred_lpm,    color="45 degree line"), size=0.7) +
  labs(x = "Predicted probability of high rating (LPM)", y="Predicted probability")+
  scale_y_continuous(expand = c(0.00,0.0), limits = c(0,1), breaks = seq(0,1,0.1)) +
  scale_x_continuous(expand = c(0.00,0.0), limits = c(0,1), breaks = seq(0,1,0.1))

```

The 45 degree line is the linear probability model, the two S-curves are the logit and probit models. Based on the eye-test, the results look similar, but let's take a look at the coefficient results in the next chart. 

```{r, echo=FALSE, warning=FALSE, fig.width=4, fig.height = 3, fig.align="center" }
# Including the marginals:
cm <- c('(Intercept)' = 'Constant')
pmodels <- list('LPM'=lpm, 'logit coeffs'=logit, 'logit marginals'=logit_marg, 'probit coeffs'=probit, 'probit marginals'=probit_marg)

msummary( pmodels ,
          fmt="%.3f",
          gof_omit = 'DF|Deviance|Log.Lik.|F|R2 Adj.|AIC|BIC|R2|PseudoR2',
          stars=c('*' = .05, '**' = .01),
          coef_rename = cm)

```
In case of logit and probit models, instead of the raw coefficients, we interpret the marginal differences, which have the same interpretation as the coefficients in case of linear probability models. 
Based on this, we can see that the three models produce very similar results.
The coefficients in case of LPM in the chart mean that if the distance takes on a value larger by 0.1 km, the probability of high rating is smaller by 1.6%. If the star has a larger value (4 instead of 3), the probability of being highly rated is 25.7% larger


## Conclusion

HERE COMES WHAT WE HAVE LEARNED AND WHAT WOULD STRENGHTEN AND WEAKEN OUR ANALYSIS.

## Appendix

Here comes all the results which are referenced and not essential for understanding the MAIN results.
